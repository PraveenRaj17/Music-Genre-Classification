{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46077d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display as dis\n",
    "from scipy.io import wavfile\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6d29f",
   "metadata": {},
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0301ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdir = os.getcwd() # Get the current project working directory\n",
    "pathTo3SecFeatures = os.path.join(pdir, \"Input\", \"Data\", \"features_3_sec.csv\")\n",
    "input_data = pd.read_csv(pathTo3SecFeatures)\n",
    "#print(pathTo3SecFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02495d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features:\n",
    "input_data.columns[2:59]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad056cea",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd34306",
   "metadata": {},
   "source": [
    "- Descrptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df48d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a5faf",
   "metadata": {},
   "source": [
    "- Correlation computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We consider the features 'mfcc1_mean' and 'mfcc2_mean'\n",
    "input_data['mfcc1_mean'].corr(input_data['mfcc2_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b336e",
   "metadata": {},
   "source": [
    "- Null values inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64fbce9",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "input_data = input_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56439160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizing outliers using boxplot\n",
    "# Example: chroma_stft_mean\n",
    "sns.boxplot(x=input_data['chroma_stft_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers and replace them with lower/upper whisker\n",
    "# Method used: Interquartile range\n",
    "for col_name in input_data.select_dtypes(exclude=['object']).columns:\n",
    "    Q1 = input_data[col_name].quantile(0.25)\n",
    "    Q3 = input_data[col_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    whisker_width = 1.5\n",
    "    lower_whisker = Q1 -(whisker_width*IQR)\n",
    "    upper_whisker = Q3 +(whisker_width*IQR)\n",
    "    #Replacing with upper whisker for upper values and lower whisker for lower values\n",
    "    count = 0\n",
    "    for val in input_data[col_name].values:\n",
    "        if val>upper_whisker or val<lower_whisker:\n",
    "            count += 1\n",
    "    input_data[col_name]=np.where(input_data[col_name]>upper_whisker,upper_whisker,np.where(input_data[col_name]<lower_whisker,lower_whisker,input_data[col_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.to_csv(os.path.join(pdir,\"Preprocessed Data\",r'preprocessed_data_3_secs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d271ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathTo3SecFeaturesPreprocessed = os.path.join(pdir,\"Preprocessed Data\",\"preprocessed_data_3_secs.csv\")\n",
    "input_data = pd.read_csv(pathTo3SecFeaturesPreprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c055c0e",
   "metadata": {},
   "source": [
    "### Creating labels, Scaling data and Splitting training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e33bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d34968",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols = input_data.iloc[:, 3:60]\n",
    "# Creating labels\n",
    "labels = input_data.iloc[:, [60]]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels.label)\n",
    "labels['categorical_label'] = le.transform(labels.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(select_cols)\n",
    "X_scaled = pd.DataFrame(np_scaled, columns = select_cols.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing\n",
    "#select_cols = input_data.iloc[:, 3:60]\n",
    "X_train, X_test, y_train, y_test = train_test_split(select_cols, labels['categorical_label'], test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a93d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7769c",
   "metadata": {},
   "source": [
    "### Establishing baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest classifier\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "predict_y = clf.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(f'Training accuracy: {accuracy_score(y_train,y_pred_train)}')\n",
    "print(f'Testing accuracy: {accuracy_score(y_test,predict_y)}')\n",
    "\n",
    "print(classification_report(y_test, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7abb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn neighbors\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_train)\n",
    "predict_y = knn_clf.predict(X_test)\n",
    "\n",
    "y_pred_train = knn_clf.predict(X_train)\n",
    "\n",
    "print(f'Training accuracy: {accuracy_score(y_train,y_pred_train)}')\n",
    "print(f'Testing accuracy: {accuracy_score(y_test,predict_y)}')\n",
    "\n",
    "print(classification_report(y_test, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian NB\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "predict_y = nb_clf.predict(X_test)\n",
    "\n",
    "y_pred_train = nb_clf.predict(X_train)\n",
    "\n",
    "print(f'Training accuracy: {accuracy_score(y_train,y_pred_train)}')\n",
    "print(f'Testing accuracy: {accuracy_score(y_test,predict_y)}')\n",
    "\n",
    "print(classification_report(y_test, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d1d12",
   "metadata": {},
   "source": [
    "### Performing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dbba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "X_train_pca = X_train\n",
    "X_test_pca = X_test\n",
    "y_train_pca = y_train\n",
    "y_test_pca = y_test\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train_pca)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_pca = scaler.transform(X_train_pca)\n",
    "X_test_pca = scaler.transform(X_test_pca)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "pca = PCA(.95)\n",
    "pca.fit(X_train_pca)\n",
    "\n",
    "X_train_pca = pca.transform(X_train_pca)\n",
    "X_test_pca = pca.transform(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69860e4c",
   "metadata": {},
   "source": [
    "#### Classification after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a6833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest after PCA\n",
    "clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(X_train_pca, y_train_pca)\n",
    "predict_y = clf.predict(X_test_pca)\n",
    "print(classification_report(y_test_pca, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test_pca, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d85deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn neighbors after PCA\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train_pca, y_train_pca)\n",
    "predict_y = knn_clf.predict(X_test_pca)\n",
    "print(classification_report(y_test_pca, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test_pca, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a28878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian NB after PCA\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train_pca, y_train_pca)\n",
    "predict_y = nb_clf.predict(X_test_pca)\n",
    "\n",
    "y_pred_train = nb_clf.predict(X_train_pca)\n",
    "\n",
    "print(f'Training accuracy: {accuracy_score(y_train_pca,y_pred_train)}')\n",
    "print(f'Testing accuracy: {accuracy_score(y_test_pca,predict_y)}')\n",
    "\n",
    "print(classification_report(y_test_pca, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test_pca, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44eef78",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d7c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier\n",
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "predict_y = xgb_clf.predict(X_test)\n",
    "\n",
    "y_pred_train = xgb_clf.predict(X_train)\n",
    "\n",
    "print(f'Training accuracy: {accuracy_score(y_train,y_pred_train)}')\n",
    "print(f'Testing accuracy: {accuracy_score(y_test,predict_y)}')\n",
    "# print(accuracy(y_test, predict_y))\n",
    "print(classification_report(y_test, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a3279",
   "metadata": {},
   "source": [
    "##### Recursive feature elimination (RFE) on XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV,mutual_info_regression\n",
    "estimator = XGBClassifier(eval_metric='merror')\n",
    "rfecv = RFECV(estimator, step=1, cv=5,scoring='accuracy',verbose=1)\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "features_drop_array = list(np.where(rfecv.support_ == False)[0])\n",
    "X_train.columns[features_drop_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf422bc7",
   "metadata": {},
   "source": [
    "##### features dropped : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d803d387",
   "metadata": {},
   "source": [
    "    ['zero_crossing_rate_var', 'mfcc11_var', 'mfcc13_var', 'mfcc14_var',\n",
    "       'mfcc15_var', 'mfcc16_var', 'mfcc17_var', 'mfcc18_var', 'mfcc19_mean',\n",
    "       'mfcc20_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c9b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(X_train.columns[features_drop_array], axis=1, inplace=True)\n",
    "X_test.drop(X_test.columns[features_drop_array], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358abaf6",
   "metadata": {},
   "source": [
    "##### Running XGBClassifier after dropping features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c193860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa\n",
    "# XGBClassifier\n",
    "xgb_clf = XGBClassifier(n_estimators=1000)\n",
    "xgb_clf.fit(X_train, y_train, eval_metric='merror')\n",
    "predict_y = xgb_clf.predict(X_test)\n",
    "# print(accuracy(y_test, predict_y))\n",
    "y_pred_train = xgb_clf.predict(X_train)\n",
    "\n",
    "print(f'Training accuracy: {accuracy_score(y_train,y_pred_train)}')\n",
    "print(f'Testing accuracy: {accuracy_score(y_test,predict_y)}')\n",
    "\n",
    "print(classification_report(y_test, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39be93",
   "metadata": {},
   "source": [
    "##### Hypertuning the parametres of XGBClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9fa33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For hyperparameter tuning\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "space={\n",
    "    'n_estimators': hp.quniform('n_estimators', 0,3000,1),\n",
    "    'reg_lambda' : hp.quniform('reg_lambda', 0,500,1),\n",
    "    }\n",
    "\n",
    "def objective(space):\n",
    "    clf=XGBClassifier(\n",
    "                    n_estimators =int(space['n_estimators']),\n",
    "                    reg_lambda = int(space['reg_lambda']),\n",
    "                    )\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"auc\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)\n",
    "\n",
    "print(f\"best params: {best_hyperparams}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc92039",
   "metadata": {},
   "source": [
    "##### Running XGBClassifier using best params : 'n_estimators': 1659.0, 'reg_lambda': 92.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a969fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa\n",
    "# XGBClassifier\n",
    "xgb_clf = XGBClassifier(n_estimators=1659, reg_lambda=92.0)\n",
    "xgb_clf.fit(X_train, y_train, eval_metric='merror')\n",
    "predict_y = xgb_clf.predict(X_test)\n",
    "# print(accuracy(y_test, predict_y))\n",
    "y_pred_train = xgb_clf.predict(X_train)\n",
    "\n",
    "print(f'Training accuracy: {accuracy_score(y_train,y_pred_train)}')\n",
    "print(f'Testing accuracy: {accuracy_score(y_test,predict_y)}')\n",
    "\n",
    "print(classification_report(y_test, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85abb0c",
   "metadata": {},
   "source": [
    "#### Permutation Importance Feature Selection on knn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4411c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(file_path_3)\n",
    "select_cols = input_data.iloc[:, 3:60]\n",
    "\n",
    "# Creating labels\n",
    "labels = input_data.iloc[:, [60]]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels.label)\n",
    "labels['categorical_label'] = le.transform(labels.label)\n",
    "\n",
    "#Scaled data\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(select_cols)\n",
    "X_scaled = pd.DataFrame(np_scaled, columns = select_cols.columns)\n",
    "\n",
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels['categorical_label'], test_size=0.33)\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "seed = 12\n",
    "\n",
    "perm = PermutationImportance(knn_clf, random_state=seed).fit(X_train, y_train, n_iter=10)\n",
    "print(\"Feature Importances using Permutation Importance\")\n",
    "eli5.show_weights(perm, feature_names = X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e37022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the permutation importances\n",
    "perm_indices = np.argsort(perm.feature_importances_)[::-1]\n",
    "perm_features = [X_train.columns.tolist()[xx] for xx in perm_indices]\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.title(\"Knn feature importance via permutation importance\")\n",
    "plt.barh(range(X_train.shape[1]), perm.feature_importances_[perm_indices])\n",
    "plt.yticks(range(X_train.shape[1]), perm_features)\n",
    "plt.ylim([X_train.shape[1], -1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5bb576",
   "metadata": {},
   "source": [
    "### Trying few more classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(file_path_3)\n",
    "select_cols = input_data.iloc[:, 3:60]\n",
    "\n",
    "# Creating labels\n",
    "labels = input_data.iloc[:, [60]]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels.label)\n",
    "labels['categorical_label'] = le.transform(labels.label)\n",
    "\n",
    "#Scaled data\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(select_cols)\n",
    "X_scaled = pd.DataFrame(np_scaled, columns = select_cols.columns)\n",
    "\n",
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels['categorical_label'], test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b8f064",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a0cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import support vector classifier \n",
    "\n",
    "from sklearn.svm import SVC  \n",
    "clf = SVC(kernel='linear') \n",
    "  \n",
    "clf.fit(X_train, y_train)\n",
    "predict_y = clf.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(f'Training accuracy: {accuracy_score(y_train,y_pred_train)}')\n",
    "print(f'Testing accuracy: {accuracy_score(y_test,predict_y)}')\n",
    "\n",
    "print(classification_report(y_test, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1bed3e",
   "metadata": {},
   "source": [
    "##### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "predict_y = clf.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(f'Training accuracy: {accuracy_score(y_train,y_pred_train)}')\n",
    "print(f'Testing accuracy: {accuracy_score(y_test,predict_y)}')\n",
    "\n",
    "print(classification_report(y_test, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a82701",
   "metadata": {},
   "source": [
    "##### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d5aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "predict_y = clf.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(f'Training accuracy: {accuracy_score(y_train,y_pred_train)}')\n",
    "print(f'Testing accuracy: {accuracy_score(y_test,predict_y)}')\n",
    "\n",
    "print(classification_report(y_test, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e559fe",
   "metadata": {},
   "source": [
    "##### LogisticRegression with L1 and L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f0e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "C = [0.01, 0.10, 1.00]\n",
    "for c in C:\n",
    "    clf_l1_LR = LogisticRegression(C=c, penalty=\"l1\", tol=0.01, solver=\"saga\")\n",
    "    clf_l2_LR = LogisticRegression(C=c, penalty=\"l2\", tol=0.01, solver=\"saga\")\n",
    "    clf_l1_LR.fit(X_train, y_train)\n",
    "    clf_l2_LR.fit(X_train, y_train)\n",
    "    predict_y_l1 = clf_l1_LR.predict(X_test)\n",
    "    predict_y_l2 = clf_l2_LR.predict(X_test)\n",
    "    y_pred_train_l1 = clf_l1_LR.predict(X_train)\n",
    "    y_pred_train_l2 = clf_l2_LR.predict(X_train)\n",
    "    print('C = ', c)\n",
    "    print(f'Training accuracy L1: {accuracy_score(y_train,y_pred_train_l1)}')\n",
    "    print(f'Testing accuracy L1: {accuracy_score(y_test,predict_y_l1)}')\n",
    "    print(f'Training accuracy L2: {accuracy_score(y_train,y_pred_train_l2)}')\n",
    "    print(f'Testing accuracy L2: {accuracy_score(y_test,predict_y_l2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf822db5",
   "metadata": {},
   "source": [
    "### RandomForestClassifier (with hypertuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55345bce",
   "metadata": {},
   "source": [
    "##### RandomForestClassifier (max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e26eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest classifier\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "predict_y = clf.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(f'Training accuracy: {accuracy_score(y_train,y_pred_train)}')\n",
    "print(f'Testing accuracy: {accuracy_score(y_test,predict_y)}')\n",
    "\n",
    "print(classification_report(y_test, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae7350a",
   "metadata": {},
   "source": [
    "##### RandomForestClassifier (without any parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predict_y = clf.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(f'Training accuracy: {accuracy_score(y_train,y_pred_train)}')\n",
    "print(f'Testing accuracy: {accuracy_score(y_test,predict_y)}')\n",
    "\n",
    "print(classification_report(y_test, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predict_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9599ca70",
   "metadata": {},
   "source": [
    "##### Hypertuning the parametres of RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8c28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter space\n",
    "\n",
    "space = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [100, 200, 300, 400,500,600]),\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 1, 15,1),\n",
    "    \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "}\n",
    "\n",
    "# define objective function\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def hyperparameter_tuning(params):\n",
    "    clf = RandomForestClassifier(**params,n_jobs=-1)\n",
    "    acc = cross_val_score(clf, X_train, y_train,scoring=\"accuracy\").mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "# Fine tune the model\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    fn=hyperparameter_tuning,\n",
    "    space = space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=100, \n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "print(\"Best: {}\".format(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168e2e2",
   "metadata": {},
   "source": [
    "##### RandomForestClassifier with the best parameters :  {'criterion': 1, 'max_depth': 14.0, 'n_estimators': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8897f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators= 300, criterion= 'entropy', max_depth= 14, )\n",
    "clf.fit(X_train, y_train)\n",
    "predict_y = clf.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(f'Training accuracy: {accuracy_score(y_train,y_pred_train)}')\n",
    "print(f'Testing accuracy: {accuracy_score(y_test,predict_y)}')\n",
    "\n",
    "print(classification_report(y_test, predict_y, target_names=labels.label.unique()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, predict_y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
